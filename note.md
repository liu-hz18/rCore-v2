# 第一章 裸机应用

## 平台与目标三元组

对于一份用某种编程语言实现的源代码而言，编译器在将其通过编译、链接得到目标文件的时候需要知道程序要在哪个 **平台** (Platform) 上运行。

这里 **平台** 主要是指**CPU类型**、**操作系统类型**和**标准运行时库**的组合。

- 如果用户态基于的内核不同，会导致系统调用接口不同或者语义不一致；
- 如果底层硬件不同，对于硬件资源的访问方式会有差异。特别是 ISA 不同的话，对上提供的指令集和寄存器都不同。

`rustc --version --verbose`打印编译器 rustc 的默认配置信息

```
rustc 1.51.0-nightly (d98d2f57d 2021-01-18)
binary: rustc
commit-hash: d98d2f57d9b98325ff075c343d2c7695b66dfa7d
commit-date: 2021-01-18
host: x86_64-unknown-linux-gnu
release: 1.51.0-nightly
LLVM version: 11.0.1
```

从其中的 host 一项可以看出默认的目标平台是 `x86_64-unknown-linux-gnu`，其中 CPU 架构是 x86_64，CPU 厂商是 unknown，操作系统是 linux，运行时库是gnu libc.

我们选择的是 `riscv64gc-unknown-none-elf`，目标三元组中的CPU 架构是 riscv64gc，厂商是 unknown，操作系统是 none，elf表示没有标准的运行时库（表明没有任何系统调用的封装支持），但可以生成ELF格式的执行程序。

**RISC-V 指令集拓展**

- RV32/64I：每款处理器都必须实现的基本整数指令集。在 RV32I 中，每个通用寄存器的位宽为 32 位；在 RV64I 中则为 64 位。它可以用来模拟 绝大多数标准指令集拓展中的指令，除了比较特殊的 A 拓展，因为它需要特别的硬件支持。
- M 拓展：提供整数乘除法相关指令。
- A 拓展：提供原子指令和一些相关的内存同步机制，这个后面会展开。
- F/D 拓展：提供单/双精度浮点数运算支持。
- C 拓展：提供压缩指令拓展。

`G` 拓展是基本整数指令集 I 再加上标准指令集拓展 `MAFD` 的总称，因此 `riscv64gc` 也就等同于 `riscv64imafdc`。

**裸机平台** (bare-metal)

Rust 有一个对 std 裁剪过后的核心库 **core**，这个库是**不需要任何操作系统支持**的，相对的它的功能也比较受限(不能使用系统调用)，但是也包含了 Rust 语言 相当一部分的核心机制，可以满足我们的大部分需求。在 Rust 语言生态中，有很多三方库也不依赖标准库 std 而仅仅依赖核心库 core，它们也可以很大程度上减轻我们的编程负担。

## 提供语义项 panic_handler

panic! 宏最典型的应用场景包括断言宏 assert! 失败或者对 `Option::None/Result::Err` 进行 `unwrap` 操作。可惜的是在核心库 core 中并没有提供， 因此我们需要自己实现 panic 处理函数。

**语义项 lang_items**

Rust 编译器内部的某些功能的实现并不是硬编码在语言内部的，而是以一种可插入的形式在库中提供。库只需要通过某种方式告诉编译器它的某个方法实现了 编译器内部的哪些功能，编译器就会采用库提供的方法来实现它内部对应的功能。通常只需要在库的方法前面加上一个标记即可。

如`#[panic_handler]`

**`start` 语义项**正代表着标准库 std 在 执行应用程序之前需要进行的一些初始化工作。我们在 `main.rs` 的开头加入设置 `#![no_main]` 告诉编译器我们没有一般意义上的 `main` 函数， 并将原来的 `main` 函数删除。在失去了 `main` 函数的情况下，编译器也就不需要完成所谓的初始化工作了。

```rust
// os/src/main.rs
#![no_std]
#![no_main]
mod lang_items;
// os/src/lang_items.rs
use core::panic::PanicInfo;

#[panic_handler]
fn panic(_info: &PanicInfo) -> ! {
    loop {}
}
```

# 重建最小化运行时

在目前广泛使用的操作系统上， 它就至少需要经历以下层层递进的初始化过程：

- 一段汇编代码对硬件进行初始化，让上层包括内核在内的软件得以运行；
- 要运行该程序的时候，内核分配相应资源，将程序代码和数据载入内存，并赋予 CPU 使用权，由此应用程序可以运行；
- 程序员编写的代码是应用程序的一部分，它需要标准库进行一些初始化工作后才能运行。

让我们从 CPU 加电后**第一条指令**开始讲起。对于裸机平台 `riscv64gc-unknown-none-elf` 而言，它的 pc 寄存器会被设置为 `0x80000000` ， 也就是说它会从这个 **物理地址** (Physical Address) 开始一条条取指并执行放置于 **物理内存** (Physical Memory) 中的指令。

在该目标平台上，物理内存以物理地址 `0x80000000` 开头的部分放置着 **引导加载程序** (Bootloader) 的代码。它的任务是对硬件进行一些 初始化工作，并跳转到一个**固定的物理地址** `0x80020000` 。

因此，我们需要保证我们负责的**初始化的代码**出现在**物理内存以物理地址 `0x80020000` 开头的地方。**在我们的初始化任务完成之后，自然需要跳转到 main 函数进行执行里面的代码，这也是 初始化任务的一个重要部分。我们还需要考虑栈的设置。

## 函数调用与栈

* RISC-V 函数调用跳转指令*

| 指令                                            | 指令功能             |
| :---------------------------------------------- | -------------------- |
| jal rd, imm[20:1]   jal rd, imm[20:1]           | rd←pc+4 pc←pc+imm    |
| jalr rd, (imm[11:0])rs   jalr rd, (imm[11:0])rs | rd←pc+4    pc←rs+imm |

在 RISC-V 架构中， 通常使用 `ra(x1)` 寄存器作为其中的` rd `，因此在函数返回的时候，只需跳转回 `ra `所保存的地址即可。

事实上在函数返回的时候我们常常使用一条 **伪指令** (Pseudo Instruction) 跳转回调用之前的位置： `ret` 。它会被汇编器翻译为 `jalr x0, 0(x1)`，含义为跳转到寄存器 `ra` 保存的物理地址，由于 `x0` 是一个恒为 0 的寄存器，在 `rd` 中保存这一步被省略。

由于我们是在 ra 寄存器中保存返回地址的，**我们要保证它在函数执行的全程不发生变化**，不然在 ret 之后就会跳转到错误的位置。事实上编译器 除了函数调用的相关指令之外确实基本上不使用 ra 寄存器。

但遗憾的是，在实际编写代码的时候我们常常会遇到函数 **多层嵌套调用** 的情形。我们将在控制流转移前后需要保持不变的寄存器集合称之为 **上下文** (Context) 或称 **活动记录** (Activation Record). 在函数调用前后需要保持不变的寄存器集合被称为**函数调用上下文**

在调用子函数之前，我们需要在 内存中的一个区域 **保存** (Save) 函数调用上下文中的寄存器；而之后我们会从内存中同样的区域读取并 **恢复** (Restore) 函数调用上下文 中的寄存器。

- 调用者：首先保存不希望在函数调用过程中发生变化的调用者保存寄存器，然后通过 jal/jalr 指令调用子函数，返回回来之后恢复这些寄存器。
- 被调用者：在函数开头保存函数执行过程中被用到的被调用者保存寄存器，然后执行函数，在退出之前恢复这些寄存器。

**为何要将函数调用上下文分成两类**：编译器可以在尽可能早的时候优化掉一些无用的寄存器保存与恢复。

我们发现无论是调用者还是被调用者，都会因调用行为而需要两段匹配的保存和恢复寄存器的汇编代码，可以分别将其称为 **开场白** (Prologue) 和 **收场白** (Epilogue)，它们会由编译器帮我们自动插入。

**调用规范** (Calling Convention) 约定在**某个指令集架构**上，**某种编程语言**的函数调用如何实现。它包括了以下内容：

1. 函数的输入参数和返回值如何传递；
2. 函数调用上下文中调用者/被调用者保存寄存器的划分；
3. 其他的在函数调用流程中对于寄存器的使用方法。

当一种语言想要调用用另一门编程语言编写的函数接口时，**编译器就需要同时清楚两门语言的调用规范**，并对寄存器的使用做出调整。

*RISC-V 寄存器功能分类*

| 寄存器组       | 保存者       | 功能                                                         |
| -------------- | ------------ | ------------------------------------------------------------ |
| a0~a7          | 调用者保存   | 用来传递输入参数。特别的 a0 和 a1 用来保存返回值。           |
| t0~t6          | 调用者保存   | 作为临时寄存器使用，在函数中可以随意使用无需保存。           |
| s0~s11         | 被调用者保存 | 作为临时寄存器使用，保存后才能在函数中使用。                 |
| zero(x0)       |              | 它恒为零，函数调用不会对它产生影响；                         |
| ra(x1)         | 调用者保存   | 它并不会在每次调用子函数的时候都保存一次，而是在函数的开头和结尾保存/恢复即可，因为在执行期间即使被覆盖也没有关系。看上去和被调用者保存寄存器保存的位置一样，但是它确实是调用者保存的。 |
| sp(x2)         | 被调用者保存 | 保存 **栈指针** (Stack Pointer)，它是一个指向了内存中已经用过的位置的一个地址。在 RISC-V 架构中，栈是从高地址到低地址增长的。在一个函数中，作为起始的开场白负责分配一块新的栈空间，其实它只需要知道需要空间的大小，然后将 sp 的值减小相应的字节数即可，于是物理地址区间 [新sp,旧sp)[新sp,旧sp) 对应的物理内存便可以被这个函数用来函数调用上下文的保存/恢复 以及其他工作，这块物理内存被称为这个函数的 **栈帧** (Stackframe)。它回收的内存一定是 *最近一次分配* 的内存 |
| gp(x3)，tp(x4) |              | 在一个程序运行期间都不会变化，因此不必放在函数调用上下文中。某些情况下 gp(x3) 寄存器保存两个数据段中间的一个位置，于是全局变量是基于 gp 加上一个偏移量来访问的。 |

![../_images/StackFrame.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/StackFrame.png)

*函数栈帧中的内容*

按照地址从高到低分别有以下内容，它们都是通过 sp 加上一个偏移量来访问的：

- ra 寄存器保存其返回之后的跳转地址，是一个调用者保存寄存器；
- 父亲栈帧的结束地址 fp，是一个被调用者保存寄存器；
- 其他被调用者保存寄存器 s1~s11；
- 函数所使用到的局部变量。

## 程序内存布局

我们可以根据文件不同部分的功能进一步把两个部分划分为更小的单位： **段** (Section) 。不同的段会被编译器放置在内存不同的位置上，这构成了程序的 **内存布局** (Memory Layout)

![../_images/MemoryLayout.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/MemoryLayout.png)

*一种典型的程序相对内存布局*

- 已初始化数据段保存程序中那些已初始化的全局数据，分为 `.rodata` 和 `.data` 两部分。前者存放只读的全局数据，通常是一些常数或者是 常量字符串等；而后者存放可修改的全局数据。
- 未初始化数据段 `.bss` 保存程序中那些未初始化的全局数据，通常由程序的加载者代为进行零初始化，也即将这块区域逐字节清零；
- **堆** (heap) 区域用来存放程序运行时动态分配的数据，如 C/C++ 中的 malloc/new 分配到的数据本体就放在堆区域，它向高地址增长；
- 栈区域 stack 不仅用作函数调用上下文的保存与恢复，每个函数作用域内的局部变量也被编译器放在它的栈帧内。它向低地址增长。

我们可以将常说的编译流程细化为**多个阶段**（虽然输入一条命令便可将它们全部完成）：

1. **编译器** (Compiler) 将每个源文件从某门高级编程语言转化为汇编语言，注意此时源文件仍然是一个 **ASCII 或其他编码的文本文件**；
2. **汇编器** (Assembler) 将上一步的每个源文件中的文本格式的指令转化为**机器码**，得到一个二进制的 **目标文件** (Object File)；
3. **链接器** (Linker) 将上一步得到的所有目标文件以及**一些可能的外部目标文件**链接在一起形成一个完整的**可执行文件**。

每个目标文件都有着自己局部的内存布局，里面含有若干个段。在链接的时候，链接器会将这些内存布局合并起来形成一个整体的内存布局。在链接的时候**汇编器**会将**外部符号**替换为**实际的地址**。

我们可以通过 **链接脚本** (Linker Script) 调整链接器的行为，使得最终生成的可执行文件的内存布局符合我们的预期。

# 手动加载、运行应用程序

看看最终可执行文件的格式：

`file os/target/riscv64gc-unknown-none-elf/release/os`

```
target/riscv64gc-unknown-none-elf/release/os: ELF 64-bit LSB executable, UCB RISC-V, version 1 (SYSV), statically linked, with debug_info, not stripped 
```

可执行文件的格式为 **可执行和链接格式** (Executable and Linkable Format, ELF)，硬件平台是 RV64 .

`riscv64-unknown-elf-readelf os/target/riscv64gc-unknown-none-elf/release/os -a   `                        查看详细信息

在 ELF 文件中， 除了程序必要的代码、数据段（它们本身都只是一些二进制的数据）之外，还有一些 **元数据** (Metadata) 描述这些段在地址空间中的位置和在 文件中的位置以及一些权限控制信息，这些元数据只能放在代码、数据段的外面。

ELF 中的内容按顺序应该是：

- ELF header
- 若干个 program header
- 程序各个段的实际数据
- 若干的 section header

由于 .bss 段需要在程序正式开始运行之前被固定初始化为零，因此在 ELF 文件中，为了节省磁盘空间，只会记录 .bss 段的位置而并不是有一块长度相等的全为零的数据。在**内核（OS）**将可执行文件加载到内存的时候，它需要负责将 .bss 所分配到的内存区域全部清零。

## bin镜像文件生成

**所有应用的 ELF** 都经过 strip 丢掉所有 ELF header 和符号变为二进制镜像文件，随后以同样的格式通过 `link_user.S` 在编译的时候直接链接到内核的数据段中。

使用 `objcopy` 二进制工具将上一步中生成的 ELF 文件删除所有 ELF header 和符号得到 `.bin` 后缀的纯二进制镜像文件。它们将被链接 进内核并由内核在合适的时机加载到内存。

## 编程练习一：backtrace

如何获得`fp`的值:

```rust
#[no_mangle]
fn func_4() {
    println!("I'm in func_4!");
    // 打印函数调用链
    let mut fp: usize;
    unsafe {
        llvm_asm!("mv x10, fp" // 指令
            : "={x10}" (fp) // 返回值
            :  // 输入参数
            : "memory"
            : "volatile"
        );
    }
    let mut ra: usize;
    loop {
        unsafe { // 根据栈帧结构计算
            ra = *((fp-8_usize) as *mut usize);
            fp = *((fp-16_usize) as *mut usize);
        }
        println!("> ra = 0x{:x}, calling inst addr = 0x{:x}", ra, ra-4_usize);
        if ra <= 0x80020010_usize {
            break;
        }
    }
}
```

注意，宏替换会把 rust_main 在编译时切分成多份代码单元，造成汇编代码阅读困难。**最好把嵌套函数调用放在rust_main的最前面。**

编译成**调试单元**:

`Makefile`

```makefile
DEBUG_KERNEL_ELF := target/$(TARGET)/debug/os
DEBUG_KERNEL_BIN := $(DEBUG_KERNEL_ELF).bin

# addr2line addr
ADDR := 0x8002000c

build-debug: env $(DEBUG_KERNEL_BIN)

$(DEBUG_KERNEL_BIN): kernel-debug
	@$(OBJCOPY) $(DEBUG_KERNEL_ELF) --strip-all -O binary $@


kernel-debug:
	@cargo build


disasm-debug:
	@$(OBJDUMP) $(DISASM) $(DEBUG_KERNEL_ELF) | less


run-debug: build-debug
ifeq ($(BOARD),qemu)
	@qemu-system-riscv64 \
		-machine virt \
		-nographic \
		-bios $(BOOTLOADER) \
		-device loader,file=$(DEBUG_KERNEL_BIN),addr=$(KERNEL_ENTRY_PA)
else
	@cp $(BOOTLOADER) $(BOOTLOADER).copy
	@dd if=$(DEBUG_KERNEL_BIN) of=$(BOOTLOADER).copy bs=128K seek=1
	@mv $(BOOTLOADER).copy $(DEBUG_KERNEL_BIN)
	@sudo chmod 777 $(K210-SERIALPORT)
	python3 $(K210-BURNER) -p $(K210-SERIALPORT) -b 1500000 $(DEBUG_KERNEL_BIN)
	miniterm --eol LF --dtr 0 --rts 0 --filter direct $(K210-SERIALPORT) 115200
endif
```

`Cargo.toml`

```toml
# 开发模板, 对应`cargo build`命令
[profile.dev]
opt-level = 0  # 控制编译器的 --opt-level 参数，也就是优化参数
debug = true   # 控制编译器是否开启 `-g` 参数
debug-assertions = true  # 控制调试断言是否开启
lto = false # forbidden Link Time Optimization
```

编译运行debug版本：

​	`make run-debug`

显示debug版本的反汇编

​	`make disasm-debug > ../output.txt`

使用`addr2line`工具

​	`make addr2line ADDR=0x80020d28`



# 第二章：批处理系统

**批处理系统** (Batch System) ：将多个程序打包到一起输入计算机。而当一个程序运行结束后，计算机会 *自动* 加载 下一个程序到内存并开始执行。这便是最早的真正意义上的操作系统。

人们希望一个程序的错误不要影响到操作系统本身，它只需要终止出错的程序，转而运行执行序列中的下一个程序即可。如果后面的 程序都无法运行就太糟糕了。这种 *保护* 操作系统不受有意或无意出错的程序破坏的机制被称为 **特权级** (Privilege) 机制，它实现了用户态和 内核态的隔离，需要软件和硬件的共同努力。

# RISC-V 特权级架构

RISC-V 架构中一共定义了 4 种特权级：

| 级别 | 编码 | 名称                                |
| ---- | ---- | ----------------------------------- |
| 0    | 00   | 机器模式 (M, Machine)               |
| 1    | 01   | 监督模式 (S, Supervisor)            |
| 2    | 10   | H, Hypervisor                       |
| 3    | 11   | 用户/应用模式 (U, User/Application) |

其中，级别的数值越小，特权级越高，掌控硬件的能力越强。

![../_images/PrivilegeStack.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/PrivilegeStack.png)

运行在 M 模式上的软件被称为 **监督模式执行环境** (SEE, Supervisor Execution Environment) ，这是站在运行在 S 模式上的软件的视角来看，它的下面也需要一层执行环境支撑，因此被命名为 SEE，它需要在相比 S 模式更高的特权级下运行， 一般情况下在 M 模式上运行。

RISC-V 架构中，只有 M 模式是必须实现的，剩下的特权级则可以根据跑在 CPU 上应用的实际需求进行调整：

- 简单的嵌入式应用只需要实现 M 模式；
- 带有一定保护能力的嵌入式系统需要实现 M/U 模式；
- 复杂的多任务系统则需要实现 M/S/U 模式。

**执行环境的其中一种功能**是在执行它支持的上层软件之前进行一些初始化工作。我们之前提到的引导加载程序会在加电后对整个系统进行 初始化，它实际上是 SEE 功能的一部分，也就是说在 RISC-V 架构上引导加载程序一般运行在 M 模式上。此外，编程语言的标准库也会在执行程序员 编写的逻辑之前进行一些初始化工作。

**执行环境的另一种功能**是对上层软件的执行进行监控管理。监控管理可以理解为，当上层软件执行的时候出现了一些情况导致需要用到执行环境中提供的功能， 因此需要暂停上层软件的执行，转而运行执行环境的代码。由于上层软件和执行环境被设计为运行在不同的特权级，这个过程也往往（而 **不一定** ） 伴随着 CPU 的 **特权级切换** 。在 RISC-V 架构中，这种与常规控制流 （顺序、循环、分支、函数调用）不同的 **异常控制流** (ECF, Exception Control Flow) 被称为 **陷入** (Trap) 。

 RISC-V 特权级定义的一些**异常**：

| Interrupt | Exception Code | Description                    |
| --------- | -------------- | ------------------------------ |
| 0         | 0              | Instruction address misaligned |
| 0         | 1              | Instruction access fault       |
| 0         | 2              | Illegal instruction            |
| 0         | 3              | Breakpoint                     |
| 0         | 4              | Load address misaligned        |
| 0         | 5              | Load access fault              |
| 0         | 6              | Store/AMO address misaligned   |
| 0         | 7              | Store/AMO access fault         |
| 0         | 8              | Environment call from U-mode   |
| 0         | 9              | Environment call from S-mode   |
| 0         | 11             | Environment call from M-mode   |
| 0         | 12             | Instruction page fault         |
| 0         | 13             | Load page fault                |
| 0         | 14             | Store/AMO page fault           |

其中断点异常 (Breakpoint) 和 **执行环境调用** (Environment call) 两个异常是通过在上层软件中执行一条特定的指令触发的：当执行 `ebreak` 这条指令的之后就会触发断点异常；而执行 `ecall` 这条指令的时候则会随着 CPU 当前所处特权级而触发不同的异常。

上图中相邻两特权级软件之间的接口正是基于这种异常 机制实现的。M 模式软件 SEE 和 S 模式的内核之间的接口被称为 **监督模式二进制接口** (SBI, Supervisor Binary Interface)，而内核和 U 模式的应用程序之间的接口被称为 **应用程序二进制接口** (Application Binary Interface)，当然它有一个更加通俗的名字—— **系统调用** (syscall, System Call) 。在该过程中有可能切换 CPU 特权级。因此只有将接口下降到**汇编指令级**才能够满足其通用性。

通用寄存器 `x0~x31` 在任何特权级 都可以任意访问，而每个特权级都对应一些特殊的 **控制状态寄存器** (CSR, Control and Status Register) 来控制该特权级的某些行为并描述 其状态， 它们必须通过特殊的特权指令才能够访问。当然特权指令不只有读写 CSR 这一种用途，还有其他功能的特权指令。

第一章提到的预编译的 `bootloader` 实际上是运行在 **M 模式下的 SEE**。本书正文中我们重点关心 S/U 特权级.

# 实现应用程序

保证应用程序的代码在 U 模式运行是我们接下来将实现的批处理系统的任务。

- `00hello_world`：在屏幕上打印一行 `Hello, world!`；
- `01store_fault`：访问一个非法的物理地址，测试批处理系统是否会被该错误影响；
- `02power`：一个略微复杂的、行为不断在计算和打印字符串间切换的程序。

`user_lib`作为 `bin` 目录下的源程序所依赖的用户库，等价于其他编程语言提供的标准库。

在 `lib.rs` 中我们定义了用户库的入口点 `_start`

```rust
#[no_mangle]
#[link_section = ".text.entry"] // Rust 的宏将 _start 这段代码编译后的汇编代码中放在一个名为 .text.entry 的代码段中，方便我们在后续链接的时候 调整它的位置使得它能够作为用户库的入口。
pub extern "C" fn _start() -> ! {
    clear_bss();
    exit(main());
    panic!("unreachable after sys_exit!");
}
```

## 内存布局

在 `user/.cargo/config` 中，我们和第一章一样设置链接时使用链接脚本 `user/src/linker.ld` 。在其中我们做的重要的事情是：

- 将程序的起始物理地址调整为 `0x80040000` ，三个应用程序都会被加载到这个物理地址上运行；
- 将 `_start` 所在的 `.text.entry` 放在整个程序的开头，也就是说批处理系统只要在加载之后跳转到 `0x80040000` 就已经进入了 用户库的入口点，并会在初始化之后跳转到应用程序主逻辑；
- 提供了最终生成可执行文件的 `.bss` 段的起始和终止地址，方便 `clear_bss` 函数使用。

## 系统调用

在子模块 `syscall` 中我们作为应用程序来通过 `ecall` 调用批处理系统提供的接口，由于应用程序运行在 U 模式， `ecall` 指令会触发 名为 `Environment call from U-mode` 的异常，并 Trap 进入 S 模式执行批处理系统针对这个异常特别提供的服务代码。这个接口可以被称为 **ABI 或者系统调用。**

*第二章新增系统调用*:

```rust
/// 功能：将内存中缓冲区中的数据写入文件。
/// 参数：`fd` 表示待写入文件的文件描述符；
///      `buf` 表示内存中缓冲区的起始地址；
///      `len` 表示内存中缓冲区的长度。
/// 返回值：返回成功写入的长度。
/// syscall ID：64
fn sys_write(fd: usize, buf: *const u8, len: usize) -> isize;

/// 功能：退出应用程序并将返回值告知批处理系统。
/// 参数：`xstate` 表示应用程序的返回值。
/// 返回值：该系统调用不应该返回。
/// syscall ID：93
fn sys_exit(xstate: usize) -> !;
```

在实际调用的时候，我们需要按照 RISC-V 调用 规范在合适的寄存器中放置系统调用的参数，然后执行 `ecall` 指令触发 Trap。

在 Trap 回到 U 模式的应用程序代码之后，会从 `ecall` 的 下一条指令继续执行，同时我们能够按照调用规范在合适的寄存器中读取返回值。

在 RISC-V 调用规范中，和函数调用的情形类似，约定寄存器 `a0~a6` 保存系统调用的参数， `a0~a1` 保存系统调用的返回值。

寄存器 `a7` 用来传递 syscall ID，这是因为所有的 syscall 都是通过 `ecall` 指令触发的，除了各输入参数之外我们还额外需要一个寄存器 来保存要请求哪个系统调用。

我们将所有的系统调用都封装成 `syscall` 函数，可以看到它支持传入 syscall ID 和 3 个参数:

```rust
// user/src/syscall.rs

fn syscall(id: usize, args: [usize; 3]) -> isize {
    let mut ret: isize;
    unsafe {
        llvm_asm!("ecall" //assembly template
            : "={x10}" (ret) //output operands
            : "{x10}" (args[0]), "{x11}" (args[1]), "{x12}" (args[2]), "{x17}" (id) //input operands
            : "memory" //clobbers
            : "volatile" //options
        );
    }
    ret
}
```

`memory`:  告知编译器插入的汇编代码会造成的一些影响以防止编译器在不知情的情况下误优化。常用的使用方法是告知编译器某个寄存器在执行嵌入 的汇编代码中的过程中会发生变化。我们这里则是告诉编译器在执行嵌入汇编代码中的时候会修改内存。这能给编译器提供更多信息。

`volatile`: 告知编译器将我们在程序中给出的嵌入汇编代码保持原样放到最终构建的可执行文件中。如果不这样做的话，编译器可能会把它和其他代码 一视同仁并放在一起进行一些我们期望之外的优化。为了保证语义的正确性，一些比较关键的汇编代码需要加上该选项。

于是 `sys_write` 和 `sys_exit` 只需将 `syscall` 进行包装：

```rust
// user/src/syscall.rs

const SYSCALL_WRITE: usize = 64;
const SYSCALL_EXIT: usize = 93;

pub fn sys_write(fd: usize, buffer: &[u8]) -> isize {
    syscall(SYSCALL_WRITE, [fd, buffer.as_ptr() as usize, buffer.len()])
}

pub fn sys_exit(xstate: i32) -> isize {
    syscall(SYSCALL_EXIT, [xstate as usize, 0, 0])
}
```

注意 `sys_write` 使用一个 **`&[u8]` 切片**类型来描述缓冲区，这是一个 **胖指针** (Fat Pointer)，里面既包含缓冲区的起始地址，还 包含缓冲区的长度。我们可以分别通过 `as_ptr` 和 `len` 方法取出它们并独立的作为实际的系统调用参数。

# 实现批处理系统

批处理系统被设计为运行在 **S 模式**，这是由作为它运行环境的 SEE 所保证的；应用程序被设计为运行在 **U 模式**，这个则是我们的批处理系统 所保证的。

## 将应用程序链接到内核

我们把应用程序的二进制镜像文件作为内核的数据段链接到内核里面，因此内核需要知道内含的应用程序的数量和它们的位置，这样才能够在运行时 对它们进行管理并能够加载到物理内存。

## 应用管理器

构体 `AppManager` 里面只是保存了 一个指向 `AppManagerInner` 的 `RefCell` 智能指针。

这样设计的原因在于：我们希望将 `AppManager` 实例化为一个全局变量使得 任何函数都可以直接访问，但是里面的 `current_app` 字段表示当前执行到了第几个应用，它会在**系统运行期间发生变化**。因此在声明全局变量 的时候一种自然的方法是利用 `static mut`。但是在 Rust 中，**任何对于 `static mut` 变量的访问都是 unsafe 的**，而我们要尽可能 减少 unsafe 的使用来更多的让编译器负责安全性检查。

于是，我们利用 `RefCell` 来提供 **内部可变性** (Interior Mutability)， 所谓的内部可变性就是指在我们只能拿到 `AppManager` 的不可变借用，意味着同样也只能拿到 `AppManagerInner` 的不可变借用的情况下依然可以修改 `AppManagerInner` 里面的字段。

使用 `RefCell::borrow/RefCell::borrow_mut` 分别可以拿到 `RefCell` 里面内容的不可变借用/可变借用， `RefCell` 内部会**运行时**维护**当前已有的借用状态**并进行借用检查。于是 `RefCell::borrow_mut` 就是我们实现内部可变性的关键。

`lazy_static!` 宏提供了全局变量的运行时初始化功能。一般情况下，全局变量必须在编译期设置一个初始值，但是有些全局变量依赖于运行期间 才能得到的数据作为初始值。这导致这些全局变量需要在运行时发生变化，也即重新设置初始值之后才能使用。

我们借助 `lazy_static!` 声明了一个名为 `APP_MANAGER` 的 `AppManager` 全局实例，且只有在它第一次被使用到 的时候才会实际进行初始化工作。

奇怪的汇编指令 `fence.i` ，它是用来清理 i-cache .

CPU 对物理内存所做的缓存又分成 **数据缓存** (d-cache) 和 **指令缓存** (i-cache) 两部分，分别在 CPU 访存和取指的时候使用。

在取指 的时候，对于一个指令地址， CPU 会先去 i-cache 里面看一下它是否在某个已缓存的缓存行内，如果在的话它就会直接从高速缓存中拿到指令而不是通过总线和内存通信。

通常情况下， CPU 会认为程序的代码段不会发生变化，因此 **i-cache 是一种只读缓存**。

但在这里，我们会修改会被 CPU 取指的内存 区域，这会使得 **i-cache 中含有与内存中不一致的内容**。因此我们这里必须使用 `fence.i` 指令手动清空 i-cache ，让里面所有的内容全部失效， 才能够保证正确性。

# 处理 Trap

批处理系统作为应用程序的执行环境，需要在执行应用程序之前进行一些初始化工作，并监控应用程序的执行:

- 当应用程序发起系统调用之后，需要到批处理系统中进行处理；
- 当应用程序执行出错的时候，需要到批处理系统中杀死该应用并加载运行下一个应用；
- 当应用程序执行结束的时候，需要到批处理系统中加载运行下一个应用（实际上也是通过系统调用 `sys_exit` 来实现的）。

通常需要注意两点：在 触发 Trap 之前 CPU 运行在哪个特权级；以及 CPU 需要切换到哪个特权级来处理该 Trap 并在处理完成之后返回原特权级。

本章中我们仅考虑 当 CPU 在 U 特权级运行用户程序的时候触发 Trap，并切换到 S 特权级的批处理系统的对应服务代码来进行处理。

在 RISC-V 架构中，关于 Trap 有一条重要的规则：**在 Trap 前后特权级不会下降**。因此如果触发 Trap 之后切换到 S 特权级（下称 Trap 到 S）， 说明 Trap 发生之前 CPU 只能运行在 S/U 特权级。

*进入 S 特权级 Trap 的相关 CSR*:

| CSR 名  | 该 CSR 与 Trap 相关的功能                                    |
| ------- | ------------------------------------------------------------ |
| sstatus | `SPP` 字段给出 Trap 发生之前 CPU 处在哪个特权级（S/U）       |
| sepc    | 当 Trap 是一个异常的时候，记录 Trap 发生之前执行的最后一条指令的地址 |
| scause  | 描述 Trap 的原因                                             |
| stval   | 给出 Trap 附加信息                                           |
| stvec   | 控制 Trap 处理代码的入口地址                                 |

`sstatus` 是 **S 特权级最重要的 CSR**，可以从很多方面控制 S 特权级的行为并描述其状态。

**stvec 相关细节**

在 RV64 中， `stvec` 是一个 64 位的 CSR，它有两个字段：

- MODE 位于 [1:0]，长度为 2 个比特；
- BASE 位于 [63:2]，长度为 62 个比特。

当 MODE 字段为 0 的时候， `stvec` 被设置为 Direct 模式，此时进入 S 的 Trap 无论原因如何，处理 Trap 的入口地址都是 BASE 字段， CPU 会跳转到这个地方。本书中我们只会将 `stvec` 设置为 Direct 模式。而 `stvec` 还可以被设置为 Vectored 模式

**sscratch CSR 的用途**

在特权级切换的时候，我们需要将 Trap 上下文保存在内核栈上，因此需要一个**寄存器暂存内核栈地址**，并以它作为基地址来依次保存 Trap 上下文 的内容。但是**所有的通用寄存器都不能够用来暂存**，因为它们都需要被保存，如果覆盖掉它们会影响应用执行流的执行。

重要的中转寄存器：**sscratch**。 在保存 Trap 上下文的时候，它 起到了**两个作用**：

​	1.保存了内核栈的地址

​	2.作为一个中转站让 sp 目前指向的用户栈的地址可以暂时保存下来

我们仅需一条 **`csrrw` 指令**就完成了从用户栈到内核栈的切换，这是一种极其精巧的实现。

### 上下文的保存

在一个固定的 CPU 上，只要有一个栈作为存储空间，我们就能以多种 普通控制流（顺序、分支、循环结构和多层嵌套函数调用）组合的方式，来一行一行的执行源代码（以编程语言级的视角），也是一条一条的执行汇编指令 （以汇编语言级的视角）.

 **执行流** (Execution of thread) 表示截止到某条指令执行完毕所有相关资源（包括寄存器、栈）的状态集合，它完整描述了自记录起始之后该执行流的指令执行历史。

在实际运行 Trap 执行流 修改这些寄存器之前，我们也需要在某个地方保存这些寄存器并在后续恢复，事实上也是在某个栈上。

除了通用寄存器之外还有一些可能在 Trap 前后被修改的 CSR，比如 CPU 所在的特权级。我们要保证它们的变化在我们的预期之内，比如对于特权级而言应该是 Trap 之前在 U 特权级，处理 Trap 的时候在 S 特权级，返回之后又需要回到 U 特权级。

而对于栈问题则相对简单，只要两个执行流用来记录执行历史的栈所对应的内存区域不相交，就不会产生令我们 头痛的覆盖问题，也就无需进行保存/恢复。

## Trap 的硬件机制

硬件主要负责特权级切换、跳转到正确的处理入口（要经过我们的设置才能正确）以及在 CSR 中保存一些只有硬件才能探测到的 Trap 相关信息。

当 CPU 执行完一条指令并准备 **Trap 到 S 特权级**的时候，硬件会自动帮我们做这些事情：

- `sstatus` 的 `SPP` 字段会被修改为 CPU 当前的特权级（U/S）。
- `sepc` 会被修改为 Trap 回来之后默认会执行的下一条指令的地址。当 Trap 是一个异常的时候，它实际会被修改成 **Trap 之前执行的最后一条指令的地址**。
- `scause/stval` 分别会被修改成这次 Trap 的原因以及相关的附加信息。
- CPU 会跳转到 `stvec` 所设置的 Trap 处理入口地址，并将当前特权级设置为 S ，然后开始向下执行。

当 CPU 完成 Trap 处理**准备返回**的时候，需要通过一条 S 特权级的特权指令 `sret` ，这一条指令就能同时完成以下功能：

- CPU 会将当前的特权级按照 `sstatus` 的 `SPP` 字段设置为 U 或者 S 
- CPU 会跳转到 `sepc` 寄存器指向的那条指令，然后开始向下执行。

## 软件实现执行流切换

在 Trap 触发的一瞬间， CPU 就会切换到 S 特权级并跳转到 `stvec` 所指示的位置。但是在正式进入 S 特权级的 Trap 处理之前，上面提到过**我们必须保存原执行流的寄存器状态，还需要换栈。**

我们在一个作为用户栈的特别留出的内存区域上保存**应用程序执行流**的历史信息，而 **Trap 执行流**则使用另一个**内核栈**。

这样使用两个不同的栈是为了**安全性**：如果两个执行流使用同一个栈，在返回之后应用程序就有能力看到 Trap 执行流的 历史信息，比如内核一些函数的地址，这样会带来安全隐患。

我们要做的是，在批处理系统中加入一段汇编代码中，**实现从用户栈切换到内核栈**， 并在**内核栈上保存应用程序执行流的寄存器状态**。

### Trap上下文保存

```rust
// os/src/trap/context.rs

#[repr(C)]
pub struct TrapContext {
    pub x: [usize; 32],
    pub sstatus: Sstatus,
    pub sepc: usize,
}
```

包含所有的通用寄存器 `x0~x31` ，还有 `sstatus` 和 `sepc` 。那么为什么需要保存它们呢？

- 对于通用寄存器而言，两条执行流运行在不同的特权级，所属的软件也可能有不同的编程语言编写，虽然在 Trap 执行流只是会执行 Trap 处理 相关的代码，但依然可能直接或间接调用很多模块，因此很难甚至不可能找出哪些寄存器无需保存。**既然如此我们就只能全部保存了。**但这里也有一些例外， 如 `x0` 被硬编码为 0 ，它自然不会有变化；还有 `tp(x4)` 除非我们手动出于一些特殊用途使用它，否则一般也不会被用到。它们无需保存， 但我们仍然在 `TrapContext` 中为它们预留空间，主要是为了后续的实现方便。
- 对于 CSR 而言，我们知道**进入 Trap 的时候，硬件会立即覆盖掉 `scause/stval/sstatus/sepc` 的全部或是其中一部分。**`scause/stval` 的情况是：它总是在 Trap 处理的第一时间就被使用或者是在其他地方保存下来了，因此**它没有被覆盖掉使得内容丢失造成不良影响的风险**。 而对于 **`sstatus/sepc` 而言，它们会在 Trap 处理的全程有意义**（在 Trap 执行流最后 `sret` 的时候还用到了它们），而且确实会出现 **Trap 嵌套**的情况使得它们的值被覆盖掉。所以我们需要将它们也一起保存下来，并**在 `sret` 之前恢复原样。**

## Trap 分发与处理

## 执行应用程序

当批处理系统初始化完成，或者是某个应用程序运行结束或出错的时候，我们要调用 `run_next_app` 函数切换到下一个应用程序。此时 CPU 运行在 S 特权级，而它希望能够切换到 U 特权级。

我们大概在运行应用程序之前要完成这些工作：

- 跳转到应用程序**入口点** `0x80040000`。
- 将使用的栈切换到**用户栈**。
- 在 `__alltraps` 时我们要求 **`sscratch` 指向内核栈**，这个也需要在此时完成。
- 从 S 特权级切换到 U 特权级，`sret`。

它们可以通过复用 `__restore` 的代码更容易的实现。我们**只需要在内核栈上压入一个相应构造的 Trap 上下文**，**再通过 `__restore`** ，就能让这些寄存器到达我们希望的状态。

**Q：sscratch 是何时被设置为内核栈顶的？**

A：

分析：第一次调用`run_next_app`之后，OS会获得第一个应用程序的信息，并借助`TrapContext::app_init_context(APP_BASE_ADDRESS, USER_STACK.get_sp())`初始化Trap上下文（包括sepc设置为`APP_BASE_ADDRESS`, `sstatus::SPP`设置为U-mode, sp设置为用户栈顶地址），之后调用`KERNEL_STACK.push_context(*TrapContext)`向内核栈压入该上下文，并返回内核栈栈顶，随后调用`__restore(*TrapContext)`, 先将`sp`指向内核栈栈顶，之后加载该上下文到对应的寄存器，最后将`sp`和`sscratch`对换，使得`scratch`**第一次**指向内核栈栈顶，`sp`指向用户栈栈顶，并通过`sret`进入用户程序并执行。

所以**显式调用`__restore(*TrapContext)`**, 肯定会将`sscratch`设置为正确的值，即内核栈栈顶地址。（这个地址由参数a0携带而来，随即被赋给sp）

之后的运行过程中，出现Trap时，会先调用`__alltraps`, 首先交换`sp`和`sscratch`，使得`sp`指向内核栈，`sscratch`指向用户栈，使得通过sp可以进行内核栈上的上下文保存。随后跳到`trap_handler(cx: &mut TrapContext)`处理异常, 参数就是指向内核栈上刚刚保存的上下文。

当 `trap_handler `返回之后, 会回到`__restore(*TrapContext)`, 这个a0参数依然指向**内核栈栈顶**，接着我们使用 `__restore` ，和上面的过程一样，同样通过`mv sp, a0`, `csrrw sp, sscratch, sp`来使得`sscratch`指向正确的内核栈栈顶，随后通过`sret`回到用户程序。

A: 所以有2种情况：

​	1. start running app by `__restore` （显式调用）

​	2.  back to U after handling trap (`trap_handler()`) （隐式调用(返回)）

# 第三章：多道程序与分时多任务

**批处理系统**的特性是：在内存中同一时间最多只需驻留一个应用。这是因为只有当一个应用出错或退出之后，批处理系统才会去将另一个应用加载到 相同的一块内存区域。上一章的时候所有应用都被加载到**一个固定的物理地址**，也是因为这个原因，内存中同时 最多只能驻留一个应用，当它运行完毕或者出错退出的时候由 `batch` 子模块加载一个新的应用来替换掉它。

**多道程序和分时多任务系统**则是在**内存中同一时间可以驻留多个应用**。所有的应用都是在系统启动的时候分别加载到 内存的不同区域中。

(本章中， 所有的应用在内核初始化的时候就一并被加载到内存中。应用的编号不再决定其被加载运行的先后顺序，而仅仅能够改变应用被加载到内存中的位置。)

在任务切换的时候只需完成任务上下文保存与恢复即可，这只是**在内存的帮助下**保存、 恢复少量通用寄存器，甚至无需访问外存，这从很大程度上降低了任务切换的开销。（注：**曾经**有一种 做法是每个应用仍然和在批处理系统中一样**独占内核之外的整块内存**，当暂停的时候，内核负责将它的代码、数据保存在**磁盘或硬盘**中，然后把即将**换入**的应用保存在磁盘上的代码、数据恢复到内存，这些都做完之后才能开始执行新的应用。不过，由于这种做法需要大量读写内存和外部存储设备，而它们的速度都比 CPU 慢上几个数量级，这导致任务切换的**开销过大**， 甚至完全不能接受。）

获取**多道程序**的代码

```
git checkout ch3-coop
```

获取**分时多任务系统**的代码

```
git checkout ch3
```

输出结果看上去有一些混乱，原因是用户程序的每个 `println!` 往往会被拆分成多个 `sys_write` 系统调用提交给内核。有兴趣的同学可以参考 `println!` 宏的实现。

**我们将应用的加载这部分功能分离出来在 `loader` 子模块中实现，应用的执行和切换则交给 `task` 子模块。**

注意，我们需要调整**每个应用**被构建时候使用的链接脚本 `linker.ld` 中的起始地址 `BASE_ADDRESS` 为它 **实际**会被内核加载并运行的地址。也就是要做到：**应用知道自己会被加载到某个地址运行**，而内核也确实能做到将它加载到那个地址。事实上，目前我们的应用是**绝对位置**而并不是位置无关的，内核也没有提供相应的重定位机制。

由于每个应用被加载到的位置都不同，也就导致它们(应用层的) `linker.ld` 中的 `BASE_ADDRESS` 都是不同的。实际上， 我们写了一个脚本 `build.py` 而不是直接 `cargo build` 构建应用。

# 任务切换

本章的核心机制——任务切换。

本章中，一个应用在运行途中便会 主动/被动交出 CPU 的使用权，此时它只能暂停执行，等到内核重新给它分配 CPU 资源之后才能恢复并继续执行。

一旦一条执行流需要支持“**暂停-继续**”，就需要提供一种执行流切换的机制。也就是在执行过程中**同步变化的资源（如寄存器、栈等）**需要保持不变，或者变化在它的预期之内。这些资源被称为上下文。

本节的任务切换是第二章的 Trap 之后的另一种异常控制流，都描述两条执行流之间的切换，如果将它和 Trap 进行比较：

- 与 Trap 不同，它**不涉及特权级切换**；
- 与 Trap 不同，它的**一部分是由编译器帮忙完成**的；
- 与 Trap 相同，它**对应用是透明**的。

事实上，它是来自两个不同应用的 Trap 执行流之间的切换。当一个应用 Trap 到 S 进行处理的时候，其 Trap 执行流可以调用一个特殊的 `__switch` 函数。这个函数表面上就是一个普通的函数调用：在 `__switch` 返回之后，将继续从调用该函数的位置继续向下执行。 但是其间却隐藏着复杂的执行流切换过程。

具体来说，调用 `__switch` 之后直到它返回前的这段时间，原 Trap 执行流会先被暂停并被 切换出去， CPU 转而运行另一个应用的 Trap 执行流。之后在时机合适的时候，原 Trap 执行流才会从某一条 Trap 执行流（很有可能不是 它之前切换到的那一条）切换回来继续执行并最终返回。

不过，从实现的角度讲， `__switch` 和一个普通的函数之间的差别仅仅是它会**换栈**。

由于之后还要恢复回来执行，我们必须保存 CPU 当前的某些寄存器，我们称它们为 **任务上下文** (Task Context)。我们将任务上下文直接压入**内核栈的栈顶**，从这一点上来说它和函数调用一样。

对于每一条被暂停的 Trap 执行流，我们都用一个名为 `task_cx_ptr` 的变量来保存它栈顶的任务上下文的地址。

```rust
TaskContext *task_cx_ptr = &task_cx;
TaskContext **task_cx_ptr2 = &task_cx_ptr;
```

Trap 执行流在调用 `__switch` 之前就需要明确知道即将切换到哪一条目前正处于暂停状态的 Trap 执行流，因此 `__switch` 有**两个参数**， 第一个参数代表它自己，第二个参数则代表即将切换到的那条 Trap 执行流。

我们同样从栈上内容的角度来看 `__switch` 的**整体流程**：

我们 假设某次 `__switch` 调用要从 Trap 执行流 A 切换到 B，一共可以分为五个阶段.

![switch-1](D:\大三下\操作系统\switch-1.png)

- 阶段 [1]：在 Trap 执行流 A 调用 `__switch` 之前，A 的内核栈上只有 Trap 上下文和 Trap 处理的调用栈信息，而 B 是之前被切换 出去的，它的栈顶还有额外的一个**任务上下文**；
- 阶段 [2]：A 在自身的内核栈上分配一块任务上下文的空间在里面保存 CPU 当前的寄存器快照。随后，我们更新 A 的 `task_cx_ptr`，只需 写入**指向它的指针 `task_cx_ptr2` 指向的内存** 即可；
- 阶段 [3]：这一步极为关键。这里读取 B 的 `task_cx_ptr` 或者说 `task_cx_ptr2` 指向的那块内存**获取到 B 的内核栈栈顶位置**，并 **复制给 `sp` 寄存器**来换到 B 的内核栈。由于内核栈保存着它迄今为止的执行历史记录，可以说 **换栈也就实现了执行流的切换** 。 正是因为这一步， `__switch` 才能做到一个函数跨两条执行流执行。
- 阶段 [4]：CPU 从 B 的内核栈栈顶取出任务上下文并恢复寄存器状态，在这之后还要进行**退栈**操作。
- 阶段 [5]：对于 B 而言， `__switch` 函数返回，可以从调用 `__switch` 的位置继续向下执行。

`__switch`完成了上述阶段2-4的过程，也就是**换栈、切换sp**。

# 多道程序 与 协作式调度

## 多道程序背景与 yield 系统调用

我们暂时考虑 CPU 只能 *单方面* 通过读取外设提供的寄存器来获取外设请求处理的状态。多道程序的思想在于：**内核同时管理多个应用**。 如果外设处理的时间足够长，那我们可以先进行任务切换去执行其他应用，在某次切换回来之后，应用再次读取设备寄存器，发现请求已经处理完毕了， 那么就可以用拿到的完整的数据继续向下执行了。

这种任务切换，是通过应用进行一个名为 **`sys_yield` 的系统调用**来实现的，这意味着它主动交出 CPU 的使用权给其他应用。这正是本节标题的后半部分“**协作式**”的含义。

一个应用会持续运行下去，直到它**主动调用** `sys_yield` 来交出 CPU 使用权。

内核将很大的权力**下放到应用**，让所有的应用**互相协作**来最终达成最大化 CPU 利用率，充分利用计算资源这一终极目标。

![../_images/multiprogramming.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/multiprogramming.png)

开始时，某个应用（蓝色）向外设提交了一个请求， 随即可以看到对应的外设（紫色）开始工作。但是它要工作相当长的一段时间，因此应用（蓝色）不会去等待它结束而是会调用 `sys_yield` 主动交出 CPU 使用权来切换到另一个应用（绿色）。另一个应用（绿色）在**执行了一段时间**之后调用了 `sys_yield` ，此时内核决定让应用（蓝色） 继续执行。它检查了一下外设的工作状态，发现请求尚未处理完，于是**再次调用 `sys_yield`** 。另一个应用（绿色）执行了一段时间之后 `sys_yield` 再次切换回这个应用（蓝色），这次的不同是**它发现外设已经处理完请求了**，于是它终于可以向下执行了。

**sys_yield 的缺点**

当应用调用它主动交出 CPU 使用权之后，它下一次再被允许使用 CPU 的时间点与**内核的调度策略**与当**前的总体应用执行情况**有关，很有可能 **远远迟于该应用等待的事件**（如外设处理完请求）**达成的时间点**。这就会造成该应用的**响应延迟不稳定**，有可能极高。比如，设想一下，**敲击键盘之后隔了数分钟之后才能在屏幕上看到字符**，这已经超出了人类所能忍受的范畴。

注意 `yield` 是 Rust 的关键字，因此我们只能将应用直接调用的接口命名为 `yield_` 

## 任务控制块与任务运行状态

我们**不能**对 应用完成的顺序**做任何假定**，并不是先加入的应用就一定会先完成。这种情况下，我们必须在内核中对**每个应用分别维护它的运行状态**，目前有如下几种：

```rust
#[derive(Copy, Clone, PartialEq)]
pub enum TaskStatus {
    UnInit, // 未初始化
    Ready, // 准备运行
    Running, // 正在运行
    Exited, // 已退出
}
// Copy: 决定该类型在按值传参/赋值的时候取移动语义还是 复制语义
```

内核还需要保存一个应用的更多信息，我们将它们都保存在一个名为 **任务控制块** (Task Control Block) 的数据结构中：

```rust
pub struct TaskControlBlock {
    pub task_cx_ptr: usize,
    pub task_status: TaskStatus,
}
```

## 任务管理器

```rust
// 全局的任务管理器来管理这些用任务控制块描述的应用
pub struct TaskManager {
    num_app: usize, // 任务管理器管理的应用的数目, 它在 TaskManager 初始化之后就不会发生变化
    // 变量与常量分离的编程风格
    inner: RefCell<TaskManagerInner>,
}
struct TaskManagerInner {
    tasks: [TaskControlBlock; MAX_APP_NUM], // 任务控制块数组
    current_task: usize, // CPU 正在执行的应用编号 
}
```

这里的 `current_task` 与第二章批处理系统中的含义不同。在**批处理系统**中，它表示一个既定的应用序列中的 执行进度，隐含着在该应用之前的都已经执行完毕，之后都没有执行；而在这里我们**只能通过它知道 CPU 正在执行哪个应用， 而不能获得其他应用的任何信息。**

![../_images/fsm-coop.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/fsm-coop.png)

## 第一次进入用户态

当一个应用即将被运行的时候，它会被 `__switch` 过来。如果它是之前被切换出去的话，那么此时它的内核栈上应该有 Trap 上下文和任务上下文，切换机制可以正常工作。但是**如果它是第一次被执行怎么办呢？**

这就需要它的内核栈上也有类似结构的内容。我们是在创建 `TaskManager` 的全局实例 `TASK_MANAGER` 的时候来进行这个初始化的。

# 分时多任务系统与抢占式调度

Attention: `ch3`比`ch3-coop`实际上就多了一个**时钟中断**和**时间片轮转算法**，以实现OS的主动调度。所以注释都加在`ch3`上了。

## 分时多任务系统的背景

**制造了一种每个应用独占整个 CPU 的 幻象**

**吞吐量** (Throughput) : 大概可以理解为在某个时间点将一组应用放进去，要求在一段固定的时间之内执行完毕的应用最多，或者是 总进度百分比最大。

所有的应用和编写应用的程序员都有这样的共识：只要 CPU 一直在做实际的工作就好。

我们可以将多道程序的调度机制分类成 **协作式调度**. s它的特征是：只要一个应用不**主动** yield 交出 CPU 使用权，它就会一直执行下去。

**抢占式调度** (Preemptive Scheduling) 则是应用 *随时* 都有**被内核切换**出去的可能。

现代的**任务调度算法**基本都是**抢占式**的，它要求每个应用只能连续执行一段时间，然后内核就会将它强制性切换出去。一般将 **时间片** (Time Slice) 作为应用连续执行时长的度量单位，每个时间片可能在毫秒量级。

调度算法需要考虑：每次在换出之前给一个应用**多少时间片**去执行，以及要**换入哪个应用**。

性能和 **公平性** (Fairness)：后者要求多个应用分到的时间片占比**不应差距过大**。

**时间片轮转算法** (RR, Round-Robin) ：

​	维护一个**任务队列**，每次从队头取出一个应用执行一个时间片，然后把它 丢到队	尾，再继续从队头取出一个应用，以此类推直到所有的应用执行完毕。

**如何计时**：依靠硬件提供的**时钟中断**来实现的

## RISC-V 架构中的中断

中断则 **异步** (Asynchronous) 于它指令的执行，也就是说中断来**自于哪个 外设**以及中断**如何触发**完全与它指令的执行无关。

对于**中断**的硬件机制：处理器会在**每执行完一条指令之后**检查一下这根线，看情况决定是继续执行接下来的指令还是进入中断处理流程。大多数情况下，指令执行的相关硬件单元和可能发起中断的电路是完全独立 **并行** (Parallel) 运行的，它们中间只有一根导线相连 ，除此之外指令执行的那些单元就完全不知道对方处于什么状态了。

| Interrupt | Exception Code | Description                   |
| --------- | -------------- | ----------------------------- |
| 1         | 1              | Supervisor software interrupt |
| 1         | 3              | Machine software interrupt    |
| 1         | 5              | Supervisor timer interrupt    |
| 1         | 7              | Machine timer interrupt       |
| 1         | 9              | Supervisor external interrupt |
| 1         | 11             | Machine external interrupt    |

RISC-V 的中断可以分成三类：

- **软件中断** (Software Interrupt)
- **时钟中断** (Timer Interrupt)
- **外部中断** (External Interrupt)

中断的特权级可以 决定该中断**是否会被屏蔽**，以及需要 Trap 到 CPU 的哪个特权级进行处理。

在判断中断是否会被屏蔽的时候，有以下规则：

- 如果中断的特权级低于 CPU 当前的特权级，则该中断会被屏蔽，不会被处理；
- 如果中断的特权级高于与 CPU 当前的特权级或相同，则需要通过相应的 CSR 判断该中断是否会被屏蔽。

以**内核所在的 S 特权级**为例，中断屏蔽相关的 CSR 有 `sstatus` 和 `sie` 。

`sstatus` 的 `sie` 为 **S 特权级 的中断使能**，能够同时控制三种中断，如果将其清零则会将它们全部屏蔽。即使 `sstatus.sie` 置 1 ，还要看 `sie` 这个 CSR，它的三个字段 `ssie/stie/seie` 分别控制 S 特权级的**软件中断、时钟中断和外部中断**的中断使能。

比如对于 S 态时钟中断 来说：

​	如果 CPU 不高于 S 特权级(S和U)，需要 `sstatus.sie` 和 `sie.stie` 均为 1 该中断才不会被屏蔽；

​	如果 CPU 当前特权级高于 S 特权级(即M态)，则该中断一定会被屏蔽。

**默认情况** 下，所有的中断都需要 Trap 到 M 特权级处理。

在正文中我们只需要了解：

- 包括**系统调用**（即来自 U 特权级的环境调用）在内的所有异常都会 **Trap 到 S 特权级处理**；
- 只需考虑 **S 特权级的时钟/软件/外部中断**，且它们都会被 **Trap 到 S 特权级处理**。

默认情况下，当 Trap 进入某个特权级之后，在 Trap 处理的过程中同特权级的中断都会被屏蔽。

- 当 Trap 发生时，`sstatus.sie` 会被保存在 `sstatus.spie` 字段中，同时 `sstatus.sie` 置零，这也就在 Trap 处理的过程中**屏蔽了所有 S 特权级的中断**；
- 当 Trap 处理完毕 `sret` 的时候， `sstatus.sie` 会恢复到 `sstatus.spie` 内的值。

也就是说，如果不去手动设置 `sstatus` CSR ，在只考虑 S 特权级中断的情况下，是不会出现 **嵌套中断** (Nested Interrupt) 的。**嵌套中断** 算是 **嵌套 Trap** 的一部分。

## 时钟中断与计时器

由于需要一种计时机制，RISC-V 架构要求处理器要有一个内置时钟，其频率一般低于 CPU 主频。

​	该计数器保存在一个 64 位的 CSR `mtime` 中，我们无需担 心它的溢出问题，在内核运行全程可以认为它是一直递增的。

​	另外一个 64 位的 CSR `mtimecmp` 的作用是：一旦计数器 `mtime` 的值超过了 `mtimecmp`，就会触发一次时钟中断。我们可以方便的通过设置 `mtimecmp` 的值来决定下一次时钟中断何时触发。

 M 特权级的 SEE 已经预留了相应的接口，我们可以调用它们来间接实现计时器的控制：

```rust
use riscv::register::time;
pub fn get_time() -> usize { // 取得当前 mtime 计数器的值
    time::read()
}
```

当一个应用运行了 10ms 之后，一个 S 特权级时钟中断就会被触发。由于应用运行在 U 特权级，且 `sie` 寄存器被正确 设置，该中断不会被屏蔽，而是 Trap 到 S 特权级内的我们的 `trap_handler` 里面进行处理，并顺利切换到下一个应用。这 便是我们所期望的抢占式调度机制。

从应用运行的结果也可以看出，三个 `power` 系列应用并没有进行 yield ，而是由**内核负责** 公平分配它们执行的时间片。

目前在等待某些事件的时候仍然需要 yield ，其中一个原因是为了**节约 CPU 计算资源**，另一个原因是**当事件依赖于其他的应用的时候** ，由于只有一个 CPU ，当前应用的等待可能永远不会结束。这种情况下需要先将它切换出去，**使得其他的应用到达它所期待的状态并 满足事件的生成条件，再切换回来。**

​	比如

```rust
// user/src/bin/03sleep.rs
// 通过 yield 来优化 轮询 (Busy Loop) 过程带来的 CPU 资源浪费。
#[no_mangle]
fn main() -> i32 {
    let current_timer = get_time();
    let wait_for = current_timer + 3000; // 等待 3000ms 然后退出
    while get_time() < wait_for {
        yield_(); // 主动交出 CPU 而不是无意义的忙等
        // 尽管我们不这样做，已有的抢占式调度还是会在它循环 10ms 之后切换到其他应用，但是这样 主动让出 能让内核给其他应用分配更多的 CPU 资源并让它们更早运行结束。
    }
    println!("Test sleep OK!");
    0
}
```



# 第四章：地址空间与页表

## 地址空间与虚拟地址

**制造了每个应用独占整个地址空间的幻象**

从内存使用的角度来看，**批处理系统**和裸机应用很相似：批处理系统的每个应用也都是独占内核之外的全部内存空间， 只不过当一个应用出错或退出之后，它所占据的内存区域会被清空，而序列中的下一个应用将自己的代码和数据放置进来。这个时期，内核提供给应用的**访存视角是一致的**，因为它们确实会在运行过程中始终独占一块固定的内存区域，每个应用开发者 都基于这一认知来规划程序的内存布局。

后来，为了降低等待 I/O 带来的无意义的 CPU 资源损耗，**多道程序**出现了。而为了提升用户的交互式体验，提高生产力，**分时多任务系统**诞生了。应用开始多出了一种“**暂停**”状态，这可能来源于它主动 yield 交出 CPU 资源，或是在 执行了足够长时间之后被内核强制性换出。

基于物理内存的**多道程序**和**分时多任务系统**的**缺点**：对于应用来说，它需要自己决定会被加载到哪个物理地址运行，直接访问真实的物理内存，这需要开发者对于硬件的特性和使用方法有更多了解，产生额外的学习成本，也会为应用的开发和调试带来不便。从 内核的角度来看，将直接访问物理内存的权力下放到应用会使得它难以对应用的访存行为进行有效管理，已有的特权级机制亦无法 阻止很多来自应用的恶意行为。

到目前为止仍被内核广泛使用的抽象被称为**地址空间**(Address Space) 。在每个应用的视角里，它自己**独占一个地址空间**，因此它可以随意规划自己的内存布局，它的 各个段也就可以分别放置在地址空间中它希望的位置。应用同样可以使用一个地址作为索引来读写自己地址空间的数据，这种地址被称为 **虚拟地址** (Virtual Address) 。事实上，**特权级机制被拓展**，使得应用不再具有通过物理地址直接访问物理内存的能力。

**设计目标**：

- *透明* ：应用开发者可以**不必了解底层真实物理内存的硬件细节**，且在非必要时也**不必关心内核的实现策略**， 最小化他们的心智负担；
- *高效* ：这层抽象至少在大多数情况下**不应带来过大的额外开销**；
- *安全* ：这层抽象应该有效**检测并阻止**应用读写其他应用或内核的代码、数据等一系列**恶意行为**。

**硬件任务**：当应用取指或者执行 一条访存指令的时候，它都是在以虚拟地址为索引读写自己的地址空间。此时，CPU 中的 **内存管理单元** (**MMU**, Memory Management Unit) 自动将这个虚拟地址进行 **地址转换** (Address Translation) 变为一个物理地址， 也就是物理内存上这个应用的数据真实被存放的位置。

**软件任务**：OS需要硬件提供一些寄存器 ，软件可以对它进行设置来控制 MMU 按照**哪个应用**的地址空间进行地址转换。于是，将应用的数据放到物理内存并进行管理，而 在**任务切换**的时候需要将控制 MMU **选用哪个应用的地址空间**进行映射的那些寄存器也一并进行**切换**，则是作为软件部分的内核需 要完成的工作。



**地址空间**只是一层抽象接口，它有**很多种具体的实现策略**。

## 分段内存管理：应用级线性映射

![../_images/simple-base-bound.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/simple-base-bound.png)

实际上是一种**线性映射**，曾经的一种做法如上图所示：每个应用的地址空间大小限制为一个固定的常数 `bound` ，也即每个应用的可用虚拟地址区间 均为 **[0,bound)**。随后，就可以以这个大小为单位，将物理内存除了内核预留空间之外的部分划分为若干 个大小相同的 **插槽** (Slot) ，每个应用的所有数据都被内核放置在其中一个插槽中，对应于物理内存上的一段连续物理地址 区间，假设其起始物理地址为 **base**，则由于二者大小相同，这个区间实际为 **[base,base+bound)**。因此地址转换很容易完成，只需检查一下虚拟地址不超过地址空间 的大小限制（此时需要借助特权级机制通过异常来进行处理），然后做一个线性映射，将虚拟地址加上 **base** 就得到了数据实际所在的物理地址。

实现简单：**MMU** 只需要 base,bound 两个寄存器，在地址转换进行比较或加法运算即可；而内核只需要在任务切换的同时切换 base寄存器（由于 bound 是一个常数）。内存 管理方面它只需考虑一组插槽的占用状态，可以用一个 **位图** (Bitmap) 来表示，随着应用的新增和退出对应**置位**或**清空**。

**缺点**：浪费的内存资源过多，不够灵活。每个应用的情况都不同，内核只能按照在它能力范围之内的**消耗内存最多** 的应用的情况来**统一指定地址空间的大小**，而其他内存需求较低的应用根本无法充分利用内核给他们分配的这部分空间。这种在地址空间**内部**无法被**充分利用**的空间被称为 **内碎片** (Internal Fragment) 。它限制了系统同时共存的应用数目。

## 分段内存管理：细粒度线性映射

内核开始以更细的粒度，也就是应用地址空间中的**一个逻辑段**作为单位来安排应用的数据在物理内存中的布局。**每个段的大小都是不同的**，我们也不再能仅仅 使用一个 bound 进行简化。当任务切换的时候，这些**寄存器**（base，bound）也需要被切换。一个段内的数据都经过**相同的线性映射**，所以对应的物理内存是连续的。使用**连续内存分配算法**。

![../_images/segmentation.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/segmentation.png)

注意到每个段都**只会在内存中占据一块与它实际所用到的大小相等的空间**。堆 的情况可能比较特殊，它的大小可能会在运行时增长，但是那需要应用通过系统调用向内核请求。也就是说这是一种**按需分配**，而 不再是内核在开始时就给每个应用分配一大块很可能用不完的内存。由此，**不再有内碎片了**。

**缺点**：因为每个段的大小都是不同的（它们可能来自不同的应用，功能也不同），内核就需要使用**更加通用、也更加复杂的连续内存分配算法**来进行**内存管理**，而不能像之前的插槽那样以一个比特为单位。**连续内存分配算法**就是每次需要分配一块连续内存来存放一个段的数据。随着一段时间的分配和回收，物理内存还剩下一些可用的连续块，其中有一些只是很小的间隙，**它们自己已经无法被 用于分配**，被称为 **外碎片** (External Fragment) 。

课上所讲到的那些算法，包括 **first-fit/worst-fit/best-fit** 或是 **buddy system**，其具体表现取决于实际的应用需求，各有优劣。

## 分页内存管理

结合上面二者的优点：

	1. 内核始终以一个**同样大小的单位**来在物理内存上放置应用地址空间中的数据，这样内核就可以 使用简单的**插槽式内存管理**，使得内存分配算法比较简单且**不会产生外碎片**；
 	2. **这个单位的大小要足够小**，从而其内部没有 被用到的内碎片的大小也足够小，尽可能提高内存利用率。

![../_images/page-table.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/page-table.png)

内核以页为单位进行物理内存管理。每个应用的地址空间可以被分成若干个（虚拟） **页面** (Page) ，而 可用的物理内存也同样可以被分成若干个（物理） **页帧** (Frame) ，**虚拟页面和物理页帧的大小相同**。分页内存管理的粒度更小，应用地址空间中的每个逻辑段都 由多个虚拟页面组成，而**每个虚拟页面在地址转换的过程中都使用一个不同的线性映射**（页的大小比段的大小更小），而不是在分段内存管理中每个逻辑段都使用一个相同的线性映射。

我们给每个虚拟页面和物理页帧一个编号，分别称为 **虚拟页号** (VPN, Virtual Page Number) 和 **物理页号** (PPN, Physical Page Number) 。每个应用都有一个不同的 **页表** (Page Table) ，里面记录了该应用地址空间中的每个虚拟页面映射到物理内存中的哪个物理页帧，即数据实际被内核放在哪里。

在页表中通过虚拟页号不仅能查到**物理页号**，还能得到**一组保护位**，它限制了应用对转换得到的物理地址对应的内存的使用方式。 最典型的如 `rwx` ， `r` 表示当前应用可以读该内存； `w` 表示当前应用可以写该内存； `x` 则表示当前应用 可以从该内存取指令用来执行。

页表里面的项数会很多，它只能作为一种被内核管理的数据结构**放在内存**中，但是 CPU 也会直接访问它来查页表， 这也就需要**内核和硬件之间关于页表的内存布局达成一致**。

# Rust 中的动态内存分配

本节我们尝试在内核中**支持动态内存分配**以待后面使用。

## 静态与动态内存分配

 **静态分配** (Static Allocation) ，这一过程来源于我们在程序中对变量的声明，在编译期由编译器完成。 

**动态分配** (Dynamic Allocation) ：放置一个大小可以随着应用的运行动态增减 的逻辑段，它的名字叫做堆。**应用**还要能够将这个段真正**管理**起来，即支持在运行的时候从里面分配一块空间来存放变量，而 在变量的生命周期结束之后，这块空间需要被回收以待后面的使用。**如果在某次分配的时候发现堆空间不足**，我们**并不会**像上一小节介绍的那样**移动变量的存放位置**让它们紧凑起来从而释放间隙用来分配 （事实上它很难做到这一点）， **一般情况下应用会直接通过系统调用**（如类 Unix 内核提供的 **`sbrk` 调用**）来向内核请求增**加它地址空间内堆的大小**，之后 就可以正常分配了。

**动态分配**允许我们构造另一种**并不一直存在也不绑定于函数调用的变量生命周期**：以 C 语言为例，可以说自 `malloc` 拿到指向 一个变量的指针到 `free` 将它回收之前的这段时间，这个变量**一直在堆上存在**。由于需要跨越函数调用，我们需要作为堆上数据代表 的变量在函数间以参数或返回值的形式进行传递，而这些变量一般都很小（如一个指针），其拷贝开销可以忽略。

动态内存分配的**缺点**在于：它背后运行着连续内存分配算法，它相比静态分配会带来一些额外的开销。如果动态分配非常频繁， 它甚至可能会成为应用的性能瓶颈。

## Rust 中的堆数据结构

1. 裸指针 `*const T/*mut T` 基本等价于 C/C++ 里面的普通指针 `T*` ，它自身的内容仅仅是一个地址。
2. 引用 `&T/&mut T` 自身的内容也仅仅是一个地址，但是 Rust 编译器会在编译的时候进行比较严格的 **借用检查** (Borrow Check) ，要求引用的生命周期必须在被借用的变量的生命周期之内，同时可变借用和不可变借用不能共存，一个 变量可以同时存在多个不可变借用，而可变借用同时最多只能存在一个。这能在编译期就解决掉很多内存不安全问题。
3. 智能指针不仅包含它指向的区域的地址，还含有一些额外的信息，属于一种**胖指针**。
   1. `Box<T>` 在创建时会在堆上分配一个类型为 `T` 的变量，它自身也**只保存在堆上的那个变量的位置**。而和裸指针或引用 不同的是，当 `Box<T>` 被回收的时候，它指向的——也就是在**堆上被动态分配的那个变量也会被回收**。通过 `as_ref` 方法可以看到它指向的数据的位置(地址)(C++: `std::unique_ptr`)
   2. `Rc<T>` 是一个**单线程上使用的引用计数类型**， **`Arc<T>` 与其功能相同，只是它可以在多线程上使用**。它提供了多所有权，也即地址空间中**同时可以存在指向同一个堆上变量的 `Rc<T>` ，它们都可以拿到指向变量的不可变引用来 访问这同一个变量。**而它同时也是一个**引用计数**，事实上**在堆上**的另一个位置维护了堆上这个变量目前**被引用了多少次**， 也就是存在多少个 `Rc<T>` 。**这个计数会随着 `Rc<T>` 的创建或复制而增加，并当 `Rc<T>` 生命周期结束被回收时减少。**当这个**计数变为零之后，这个计数变量本身以及被引用的变量都会从堆上被回收。**（c++：`std::shared_ptr`）
   3. `Mutex<T>` 是一个**互斥锁**，在多线程中使用，它可以**保护里层被动态分配到堆上的变量同一时间只有一个线程能对它 进行操作，从而避免数据竞争**，这是并发安全的问题，会在后面详细说明。同时，它能够提供 [内部可变性](https://rcore-os.github.io/rCore-Tutorial-Book-v3/chapter2/3batch-system.html#term-interior-mutability) 。`Mutex<T>` 时常和 `Arc<T>` 配套使用，因为它是用来 保护多个线程可能同时访问的数据，其**前提就是多个线程都拿到指向同一块堆上数据的 `Mutex<T>`** 。于是，要么就是 这个 `Mutex<T>` 作为全局变量被分配到数据段上，要么就是我们需要将 `Mutex<T>` **包裹上一层多所有权**变成 `Arc<Mutex<T>>` ，**让它可以在线程间进行传递**。请记住 `Arc<Mutex<T>>` 这个经典组合，我们后面会经常用到。
   4. 注：之前我们通过 `RefCell<T>` 来获得内部可变性。可以将 `Mutex<T>` 看成 `RefCell<T>` 的多线程版本， 因为 `RefCell<T>` 是只能在单线程上使用的。而且 `RefCell<T>` 并不会在堆上分配内存，它**仅用到静态内存 分配**。

对于 Rust 而言，我们则可以直接使用以下**容器**：

- 向量 `Vec<T>` 类似于 C++ 中的 `std::vector` ；通过  `as_ptr` 方法可以看到它指向的数据的位置(地址)
- 有序键值对容器 `BTreeMap<K, V>` 类似于 C++ 中的 `std::map` ；
- 有序集合 `BTreeSet<T>` 类似于 C++ 中的 `std::set` ；
- 链表 `LinkedList<T>` 类似于 C++ 中的 `std::list` ；
- 双端队列 `VecDeque<T>` 类似于 C++ 中的 `std::deque` 。
- 变长字符串 `String` 类似于 C++ 中的 `std::string` 。

![../_images/rust-containers.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/rust-containers.png)

## 在内核中支持动态内存分配

核心库 `core` 也**并没有动态内存分配**的功能，这个时候就要考虑利用 `alloc` 了。

`alloc` 需要我们提供给它一个全局的动态内存分配器，它会利用该分配器来管理堆空间，从而它提供的数据结构可以正常 工作。我们的动态内存分配器需要实现它提供的 `GlobalAlloc` Trait，这个 Trait 有两个必须实现的抽象接口, 类似 C 语言中的 `malloc/free`：

```rust
// alloc::alloc::GlobalAlloc

pub unsafe fn alloc(&self, layout: Layout) -> *mut u8;
pub unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout);
```

`alloc::alloc::Layout` 类型的参数， 它指出了分配的需求，分为两部分，分别是**所需空间的大小 `size` ，以及返回地址的对齐要求 `align`** 。这个对齐要求 必须是一个 2 的幂次，单位为字节数，限制**返回的地址必须是 `align` 的倍数**。

由于该 分配器的实现比较复杂，我们这里直接使用一个已有的伙伴分配器实现。`buddy_system_allocator `. 只需将我们的动态内存分配器类型**实例化为一个全局变量**，并使用 `#[global_allocator]` 语义项标记即可。

# 实现 SV39 多级页表机制

## 虚拟地址和物理地址

**默认情况下 MMU 未被使能**，此时无论 CPU 位于哪个特权级，访存的地址都会作为一个**物理地址**交给对应的内存控制单元来直接 访问物理内存。

我们可以通过修改 **S 特权级**的一个名为 **`satp` 的 CSR** 来**启用分页**模式，在这之后 **S 和 U 特权级的访存 地址会被视为一个虚拟地址**，它需要经过 MMU 的地址转换变为一个物理地址，再通过它来访问物理内存；

![../_images/satp.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/satp.png)

当 **`MODE` 设置为 0** 的时候，代表所有访存都被视为**物理地址**；而**设置为 8** 的时候，SV39 分页机制被启用，所有 S/U 特权级的访存被视为一个 **39 位的虚拟地址**，它们需要先经过 MMU 的地址转换流程， 如果顺利的话，则会变成一个 **56 位的物理地址**来访问物理内存；否则则会触发异常，这体现了该机制的内存保护能力。 

其中的 `PPN` 字段指的就是**多级页表根节点**所在的**物理页号**。

**39 位的虚拟地址可以用来访问理论上最大 512GB 的地址空间**， 而 **56 位的物理地址**在理论上甚至可以访问一块大小比这个地址空间的还高出几个数量级的物理内存。但是实际上无论是 虚拟地址还是物理地址，真正有意义、能够通过 MMU 的地址转换或是 CPU 内存控制单元的检查的地址仅占其中的很小 一部分，因此**它们的理论容量上限在目前都没有实际意义**。

![../_images/sv39-va-pa.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/sv39-va-pa.png)

采用分页管理，**单个页面的大小设置为 4KiB** ，每个虚拟页面和物理页帧都对齐到这个页面大小。4KiB 需要用 **12 位字节地址** 来表示。

**地址转换**是**以页为单位进行**的，在地址转换的前后地址的页内偏移部分不变。**在我们切换任务的时候， `satp` 也必须被同时切换。**

**注意**： `SV39` 分页模式规定 `64` 位**虚拟地址的 `[63:39]` 这 25 位必须和第 38 位相同**，否则 MMU 会直接认定它是一个 **不合法的虚拟地址**。通过这个检查之后 MMU 再取出后 39 位尝试将其转化为一个 56 位的物理地址。

也就是说，所有 2^64 个虚拟地址中，只有最低的 256GiB （当第 38 位为 0 时） 以及最高的 256GiB （当第 38 位为 1 时）是可能通过 MMU 检查的。它们已经巨大的超乎想象了.

#### Rust类型转换：

请注意，**解引用 `Deref`** Trait 是 Rust 编译器**唯一允许的一种隐式类型转换**，而对于其他的类型转换，我们必须手动 调用类型转化方法或者是显式给出转换前后的类型。

**类型转换之 From 和 Into**

一般而言，当我们为类型 `U` 实现了 `From<T>` Trait 之后，可以使用 `U::from(_: T)` 来从一个 `T` 类型的实例来构造一个 `U` 类型的实例；

而当我们为类型 `U` 实现了 `Into<T>` Trait 之后，对于一个 `U` 类型的实例 `u` ，可以使用 `u.into()` 来将其转化为一个类型为 `T` 的实例。

**实现上的细节：**

物理页号到物理地址的转换只需左移 12 位即可，但是**物理地址需要 保证它与页面大小对齐才能通过右移转换为物理页号**。

对于**不对齐**的情况，物理地址不能通过 `From/Into` 转换为物理页号，而是需要通过它自己的 `floor` 或 `ceil` 方法来 进行**下取整或上取整**的转换。

## 页表项

**物理页号和全部的标志位**以某种固定的格式保存在一个结构体中，它被称为 **页表项** (PTE, Page Table Entry) ，是利用虚拟页号在页表中查到的结果。

![../_images/sv39-pte.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/sv39-pte.png)

其中 `[53:10]` 这 44 位是物理页号，最低的 8 位 `[7:0]` 则是标志位

- 仅当` V(Valid) `位为 1 时，页表项才是**合法**的；
- `R/W/X` 分别控制索引到这个页表项的对应虚拟页面是否允许**读/写/取指**；
- `U` 控制索引到这个页表项的对应**虚拟页面**是否在 CPU 处于 **U 特权级**的情况下是否被**允许访问**；
- `G `我们暂且不理会；
- `A`(Accessed) 记录**自从页表项上的这一位被清零**之后，页表项的**对应虚拟页面是否被访问过**；
- `D`(Dirty) 则记录**自从页表项上的这一位被清零之后**，**页表项的对应虚拟页表是否被修改过**。

[bitflags](https://docs.rs/bitflags/1.2.1/bitflags/) 是一个 Rust 中常用来比特标志位的 crate 。它提供了 一个 `bitflags!` 宏，如上面的代码段所展示的那样，可以将一个 `u8` 封装成一个标志位的集合类型，支持一些常见的集合 运算。

## 多级页表原理

页表的一种最简单的实现是**线性表**，也就是按照**地址从低到高、输入的虚拟页号从 0 开始递增的顺序依次在内存中** （我们之前提到过页表的容量过大无法保存在 CPU 中）放置每个虚拟页号对应的页表项。

由于**每个页表项的大小是 8 字节**，我们只要知道第一个页表项（对应虚拟页号 0 ）被放在的**物理地址 `base_addr`** ，就能 直接计算出每个输入的虚拟页号**对应的页表项所在的位置**。

<img src="https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/linear-table.png" alt="../_images/linear-table.png" style="zoom:50%;" />

由于虚拟页号有 `2^27` 种，每个虚拟页号对应一个 `8` 字节的页表项，则每个页表都需要消耗掉 `1GiB` 内存！应用的数据还需要保存在内存的其他位置，这就使得每个应用要吃掉 `1GiB` 以上的内存。

**线性表的问题**在于：它保存了所有虚拟页号对应的页表项，但是高达 `512GiB` 的地址空间中真正会被应用 使用到的只是其中**极小的一个子集**. 由此线性表的绝大部分空间 其实都是被浪费掉的。

那么如何进行优化呢？核心思想就在于**按需分配**:  

​		这是因为，每个应用的地址空间最开始都是空的，或者说**所有的虚拟页号均不合法**，那么这样的页表 自然不需要占用任何内存， MMU 在地址转换的时候无需关心页表的内容而是将所有的虚拟页号**均判为不合法**即可。而在后面， 内核已经决定好了一个应用的各逻辑段存放位置之后，它就需要负责从零开始以虚拟页面为单位来让该应用的地址空间的某些部分 变得合法，反映在该应用的**页表上**也就是**一对对映射顺次被插入进来**，自然页表所占据的内存大小也就**逐渐增加**。

**多级页表**（Multi-Level Page-Table）：事实上 `SV39 `分页机制等价于一颗**字典树**（**三级页表**）。 `27` 位的 **虚拟页号**可以看成一个长度 `n=3` 的字符串，字符集为 `α={0,1,2,...,511}` ，因为每一位字符都 由 **9 个比特**组成。**每个叶节点**都需要保存` 512` 个 `8` 字节的页表项，一共正好 `4KB` （512 x 8 = 4096 byte = 4KB）, 可以直接放在一个物理页帧内.  而对于非叶节点来说，从功能上它只需要保存 `512` 个指向下级节点的指针即可， 不过我们就像叶节点那样**也保存 `512` 个页表项**，这样所有的节点都可以被放在**一个物理页帧**内，**它们的位置可以用一个 物理页号来代替**。

非叶节点的页表项标志位含义和叶节点相比有一些不同：

- 当 V 为 0 的时候，代表当前字符指针是一个空指针，无法走向下一级节点；
- 只有当 R/W/X 均为 0 的时候才能向下走（事实上正确的说法应该是：**只要 R/W/X 不全为 0 就会停下来**，**直接从当前的页表项中取出物理页号进行最终的地址转换**）。在这里我们给出 SV39 中的 R/W/X 组合的含义：

![../_images/pte-rwx.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/pte-rwx.png)

 **大页** (Huge Page)：

​	在 SV39 中，如果使用了一级页索引就停下来，则它可以涵盖虚拟页号的前 `9` 位为某一固定值的所有虚拟地址， 对应于一个 `1GiB` 的大页；如果使用了二级页索引就停下来，则它可以涵盖虚拟页号的前 `18` 位为某一固定值的所有虚拟地址，对应于一个 `2MiB` 的大页。以同样的视角，如果使用了 所有三级页索引才停下来，它可以涵盖虚拟页号为某一个固定值的所有虚拟地址，自然也就对应于一个大小为 `4KiB` 的虚拟页面。

​	使用**大页的优点**在于，当地址空间的大块连续区域的访问权限均相同的时候，可以直接映射一个大页，从时间上避免了大量页表项的索引(查找)和修改，从空间上降低了所需节点的数目。

​	但是，从内存分配算法的角度，这需要内核支持**从物理内存上分配三种不同大小的连续区域**（ 4KiB 或是另外两种大页），便不能使用更为简单的插槽式管理。本书全程只会以 `4KiB` 为单位进行页表映射

### **分析 SV39 多级页表的内存占用**

我们知道，**多级页表的总内存消耗取决于节点的数目**，每个节点 则需要一个大小为 `4KiB` 物理页帧存放。不妨设某个应用地址空间中的实际用到的总空间大小为 `S` 字节，则多级页表所需的内存至少有这样两个上界：

- 每映射一个 `4KiB` 的**虚拟页面**，**最多需要新分配两个物理页帧**来保存新的节点，加上**初始就有一个根节点**， 因此消耗内存不超过`4KiB×(1+2S/4KiB) = 4KiB+2S`
- 考虑**已经映射了很多虚拟页面**，使得根节点的 `512` 个孩子节点都已经被分配的情况，此时**最坏的情况是每次映射都需要分配一个不同的最深层节点**，加上根节点的所有孩子节点并不一定都被分配，从这个角度来讲消耗内存不超过 `4KiB×(1+512+S/4KiB) = 4KiB+2MiB+S `

虽然这两个上限都可以通过刻意构造一种地址空间的使用来达到，但是它们看起来很不合理，因为它们均大于 S ，也就是 **元数据比数据还大**。

其实，**真实环境中一般不会有如此极端的使用方式**，更加贴近 实际的是下面一种上限：即**除了根节点的一个物理页帧**之外，地址空间中的每个实际用到的大小为 **`T` 字节**的 ***连续* 区间** 会让多级页表额外消耗不超过 `4KiB × (⌈T/2MiB⌉ + ⌈T/1GiB⌉)`的内存。括号中的两项分别对应 为了映射这段连续区间所需要新分配的**最深层**和**次深层**节点的数目，**前者每连续映射 2MiB (12 bit) 才会新分配一个**，而**后者每连续映射 1GiB (21 bit) 才会新分配一个**。由于后者远小于前者， 可以将后者忽略，最后得到的结果近似于 `T/512`.  而**一般情况**下我们对于地址空间的使用方法都是**在其中 放置少数几个连续的逻辑段**，因此当一个地址空间实际使用的区域大小**总和为 `S` 字节**的时候，**我们可以认为为此多级页表 消耗的内存在 `S/512` 左右**。相比线性表固定消耗 `1GiB` 的内存，这已经相当可以接受了。

​	![../_images/sv39-full.png](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/sv39-full.png)

 **从内存中得到物理地址需要4次访存。**

## 物理页帧管理

**物理页帧**的重要性：它既可以用来实际存放应用的数据，也能够用来存储某个应用多级页表中的一个节点。 

#### **在单核环境下使用 Mutex\<T> 的原因**

目前我们的内核运行在**单 CPU** 上，且 Trap 进入内核之后并没有手动打开中断，这也就 使得**同一时间最多只有一条 Trap 执行流并发访问内核的各数据结构**，此时应该是并没有任何数据竞争风险的。那么 加锁的原因其实有两点：

1. **在不触及 `unsafe` 的情况下实现 `static mut` 语义**。如果读者还有印象， [前面章节](https://rcore-os.github.io/rCore-Tutorial-Book-v3/chapter2/3batch-system.html#term-interior-mutability) 我们使用 `RefCell<T>` 提供了内部可变性去掉了 声明中的 `mut` ，然而麻烦的在于 `static` ，**在 Rust 中一个类型想被实例化为一个全局变量，则 该类型必须先告知编译器自己某种意义上是线程安全的，这个过程本身是 `unsafe` 的**。

   因此我们直接使用 `Mutex<T>` ，它既**通过 `lock` 方法提供了内部可变性**，又已经在模块内部**告知了编译器它的线程安全性**。这样 `unsafe` 就被隐藏在了 `spin` crate 之内，我们无需关心。这种风格 是 Rust 所推荐的。

2. 方便后续拓展到真正存在数据竞争风险的多核环境下运行。

